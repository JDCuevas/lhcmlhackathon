{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i2.wp.com/www.ai-claudio.com/wp-content/uploads/2017/05/keras-tensorflow-logo.jpg?resize=500%2C201\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "import h5py\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import TruncatedNormal\n",
    "from keras.layers import Flatten, MaxPooling2D\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%run CapsNet.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_init     = 1.e-3    # Initial learning rate  \n",
    "batch_size  = 64       # Training batch size\n",
    "train_size  = 1024     # Training size\n",
    "valid_size  = 1024     # Validation size\n",
    "test_size   = 1024     # Test size\n",
    "epochs      = 20       # Number of epochs\n",
    "doGPU       = False    # Use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if doGPU:\n",
    "    import tensorflow as tf\n",
    "    from keras.backend.tensorflow_backend import set_session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth=True\n",
    "    set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Image Data\n",
    "### Two classes of particles: electrons and photons \n",
    "### Images from 32x32 matrices of energies in each calorimeter cell (one cell = one pixel) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols, nb_channels = 32, 32, 2     \n",
    "nb_classes = 2 # Photon (0) or Electron (1)\n",
    "input_dir = 'data'\n",
    "decays = ['SinglePhotonPt50_IMGCROPS_n249k_RHv1', 'SingleElectronPt50_IMGCROPS_n249k_RHv1']\n",
    "\n",
    "def load_data(decays, start, stop):\n",
    "    global input_dir\n",
    "    dsets = [h5py.File('%s/%s.hdf5'%(input_dir,decay)) for decay in decays]\n",
    "    X = np.concatenate([dset['/X'][start:stop] for dset in dsets])\n",
    "    y = np.concatenate([dset['/y'][start:stop] for dset in dsets])\n",
    "    assert len(X) == len(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Training/Validation/Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set range of training set\n",
    "train_start, train_stop = 0, train_size\n",
    "assert train_stop > train_start\n",
    "assert (len(decays)*train_size) % batch_size == 0\n",
    "X_train, y_train = load_data(decays,train_start,train_stop)\n",
    "\n",
    "# Set range of validation set\n",
    "valid_start, valid_stop = 160000, 160000+valid_size\n",
    "assert valid_stop  >  valid_start\n",
    "assert valid_start >= train_stop\n",
    "X_valid, y_valid = load_data(decays,valid_start,valid_stop)\n",
    "\n",
    "# Set range of test set\n",
    "test_start, test_stop = 204800, 204800+test_size\n",
    "assert test_stop  >  test_start\n",
    "assert test_start >= valid_stop\n",
    "X_test, y_test = load_data(decays,test_start,test_stop)\n",
    "\n",
    "samples_requested = len(decays) * (train_size + valid_size + test_size)\n",
    "samples_available = len(y_train) + len(y_valid) + len(y_test)\n",
    "assert samples_requested == samples_available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot  sample of training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAACSCAYAAADckaYRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nE9yDxcqbnQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faa15a4dfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.imshow(X_train[1,:,:,0])\n",
    "plt.title(\"Channel 0\")  # Energy\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.imshow(X_train[1,:,:,1])\n",
    "plt.title(\"Channel 1\")  # Time\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "softmax() got an unexpected keyword argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1c2c047412b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Define CNN Model ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCAPSNET\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-07d306049856>\u001b[0m in \u001b[0;36mCAPSNET\u001b[0;34m(input_shape, nb_class)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;31m# Layer 3: Capsule layer. Routing algorithm runs here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0mparticlescap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCapsuleLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_capsule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_capsule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroutings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'particlescap'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimarycaps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;31m# Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_93/x86_64-centos7-gcc7-opt/lib/python2.7/site-packages/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-07d306049856>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroutings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;31m# c.shape=[batch_size, num_capsule, input_num_capsule]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;31m# c.shape =  [batch_size, num_capsule, input_num_capsule]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: softmax() got an unexpected keyword argument 'axis'"
     ]
    }
   ],
   "source": [
    "### Define CNN Model ###\n",
    "\n",
    "model, eval_model = CAPSNET((img_rows, img_cols, nb_channels), nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1.e-6)\n",
    "history=model.fit(X_train, y_train,\\\n",
    "        batch_size=batch_size,\\\n",
    "        epochs=epochs,\\\n",
    "        validation_data=(X_valid, y_valid),\\\n",
    "        callbacks=[reduce_lr],\\\n",
    "        verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "score = model.evaluate(X_valid, y_valid, verbose=1)\n",
    "print('\\nValidation loss / accuracy: %0.4f / %0.4f'%(score[0], score[1]))\n",
    "y_pred = model.predict(X_valid)\n",
    "fpr, tpr, _ = roc_curve(y_valid, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('Validation ROC AUC:', roc_auc)\n",
    "\n",
    "# Evaluate on test set\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('\\nTest loss / accuracy: %0.4f / %0.4f'%(score[0], score[1]))\n",
    "y_pred = model.predict(X_test)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('Test ROC AUC:', roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.legend(loc=2, prop={'size': 15})\n",
    "plt.plot(fpr, tpr, label='Model 1 (ROC-AUC = {:.3f})'.format(roc_auc))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
